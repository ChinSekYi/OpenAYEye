{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns of the csv file to english readeable names, in addition the dataset used here is a subset of the original dataset, the original dataset train is 13,647,000 rows and test is 900,000 rows, loading it in will crash your computer. \n",
    "### Currently the train file in spanish is named sandenter_train_small and test is sandenter_test_small. The code uses sandenter_train_small as it has enough rows to do both train and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from statistics import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully relabelled and saved to renamed_reco_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating a new file to for the translated version, this is solely for visualisation purposes and is not used. \n",
    "# The original spanish verison will be used.\n",
    "\n",
    "csv_file_path = \"sandenter_train_small.csv\"  # input CSV file\n",
    "output_file_path = \"renamed_reco_train.csv\"  # output CSV file\n",
    "\n",
    "# Define the mapping of original Spanish column names to English column names\n",
    "column_mapping = {\n",
    "    \"fecha_dato\": \"report_date\",\n",
    "    \"ncodpers\": \"customer_id\",\n",
    "    \"ind_empleado\": \"employee_index\",\n",
    "    \"pais_residencia\": \"country_residence\",\n",
    "    \"sexo\": \"gender\",\n",
    "    \"age\": \"age\",\n",
    "    \"fecha_alta\": \"contract_start_date\",\n",
    "    \"ind_nuevo\": \"new_customer_index\",\n",
    "    \"antiguedad\": \"seniority_months\",\n",
    "    \"indrel\": \"primary_customer_status\",\n",
    "    \"ult_fec_cli_1t\": \"last_primary_customer_date\",\n",
    "    \"indrel_1mes\": \"customer_type_start_month\",\n",
    "    \"tiprel_1mes\": \"customer_relation_type\",\n",
    "    \"indresi\": \"residence_index\",\n",
    "    \"indext\": \"foreigner_index\",\n",
    "    \"conyuemp\": \"spouse_employee_index\",\n",
    "    \"canal_entrada\": \"join_channel\",\n",
    "    \"indfall\": \"deceased_index\",\n",
    "    \"tipodom\": \"address_type\",\n",
    "    \"cod_prov\": \"province_code\",\n",
    "    \"nomprov\": \"province_name\",\n",
    "    \"ind_actividad_cliente\": \"activity_index\",\n",
    "    \"renta\": \"gross_income\",\n",
    "    \"segmento\": \"customer_segment\",\n",
    "    \"ind_ahor_fin_ult1\": \"saving_account\",\n",
    "    \"ind_aval_fin_ult1\": \"guarantee\",\n",
    "    \"ind_cco_fin_ult1\": \"current_account\",\n",
    "    \"ind_cder_fin_ult1\": \"derivada_account\",\n",
    "    \"ind_cno_fin_ult1\": \"payroll_account\",\n",
    "    \"ind_ctju_fin_ult1\": \"junior_account\",\n",
    "    \"ind_ctma_fin_ult1\": \"more_particular_account\",\n",
    "    \"ind_ctop_fin_ult1\": \"particular_account\",\n",
    "    \"ind_ctpp_fin_ult1\": \"particular_plus_account\",\n",
    "    \"ind_deco_fin_ult1\": \"short_term_deposits\",\n",
    "    \"ind_deme_fin_ult1\": \"medium_term_deposits\",\n",
    "    \"ind_dela_fin_ult1\": \"long_term_deposits\",\n",
    "    \"ind_ecue_fin_ult1\": \"e_account\",\n",
    "    \"ind_fond_fin_ult1\": \"funds\",\n",
    "    \"ind_hip_fin_ult1\": \"mortgage\",\n",
    "    \"ind_plan_fin_ult1\": \"pensions\",\n",
    "    \"ind_pres_fin_ult1\": \"loans\",\n",
    "    \"ind_reca_fin_ult1\": \"taxes\",\n",
    "    \"ind_tjcr_fin_ult1\": \"credit_card\",\n",
    "    \"ind_valo_fin_ult1\": \"securities\",\n",
    "    \"ind_viv_fin_ult1\": \"home_account\",\n",
    "    \"ind_nomina_ult1\": \"payroll\",\n",
    "    \"ind_nom_pens_ult1\": \"pensions_payments\",\n",
    "    \"ind_recibo_ult1\": \"direct_debit\"\n",
    "}\n",
    "\n",
    "# Read the original CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#Drop the useless columns (correlation matrix used https://medium.com/@samarthjoelram/santander-recommendation-system-cab6b40596b5)\n",
    "# List of columns to drop if they exist\n",
    "columns_to_drop = ['ult_fec_cli_1t', 'ind_actividad_cliente', 'cod_prov', 'conyuemp', 'tipodom']\n",
    "# Drop columns if they exist in the DataFrame\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "# Rename the columns to english\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file successfully relabelled and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making changes to spanish datafile to suit our needs, the simplified dataset is the one we assume is collected by \n",
    "#companies.\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the renamed CSV file\n",
    "csv_file_path = \"renamed_reco_train.csv\"\n",
    "\n",
    "# Read the renamed CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define new column names\n",
    "fixed_deposits_col = 'fixed_deposits'\n",
    "loan_col = 'loan'\n",
    "credit_card_debit_card_col = 'credit_card_debit_card'\n",
    "account_col = 'account'\n",
    "\n",
    "# Check and create a new column for fixed deposits, if it doesn't exist\n",
    "if fixed_deposits_col not in df.columns:\n",
    "    deposit_columns = [\n",
    "        \"short_term_deposits\",  # ind_deco_fin_ult1\n",
    "        \"medium_term_deposits\",  # ind_deme_fin_ult1\n",
    "        \"long_term_deposits\"    # ind_dela_fin_ult1\n",
    "    ]\n",
    "    df[fixed_deposits_col] = df[deposit_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for loans, if it doesn't exist\n",
    "if loan_col not in df.columns:\n",
    "    loan_columns = [\n",
    "        \"loans\",                # ind_pres_fin_ult1\n",
    "        \"pensions\"             # ind_plan_fin_ult1\n",
    "    ]\n",
    "    df[loan_col] = df[loan_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for credit and debit cards, if it doesn't exist\n",
    "if credit_card_debit_card_col not in df.columns:\n",
    "    credit_card_columns = [\n",
    "        \"credit_card\",         # ind_tjcr_fin_ult1\n",
    "        \"direct_debit\"        # ind_recibo_ult1\n",
    "    ]\n",
    "    df[credit_card_debit_card_col] = df[credit_card_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for all accounts combined, if it doesn't exist\n",
    "if account_col not in df.columns:\n",
    "    account_columns = [\n",
    "        \"saving_account\",      # ind_ahor_fin_ult1\n",
    "        \"current_account\",     # ind_cco_fin_ult1\n",
    "        \"derivada_account\",    # ind_cder_fin_ult1\n",
    "        \"payroll_account\",     # ind_cno_fin_ult1\n",
    "        \"junior_account\",      # ind_ctju_fin_ult1\n",
    "        \"more_particular_account\",  # ind_ctma_fin_ult1\n",
    "        \"particular_account\",   # ind_ctop_fin_ult1\n",
    "        \"particular_plus_account\", # ind_ctpp_fin_ult1\n",
    "        \"e_account\",           # ind_ecue_fin_ult1\n",
    "        \"funds\",               # ind_fond_fin_ult1\n",
    "        \"home_account\",        # ind_viv_fin_ult1\n",
    "    ]\n",
    "    df[account_col] = df[account_columns].any(axis=1).astype(int)\n",
    "    \n",
    "# List of columns to drop, we merged these columns for to keep it simple to present \n",
    "# The model used for commercial purposes does not merge the products together\n",
    "columns_to_drop = [\n",
    "    'saving_account', 'guarantee', 'current_account', 'derivada_account', 'payroll_account', \n",
    "    'junior_account', 'more_particular_account', 'particular_account', 'particular_plus_account', \n",
    "    'short_term_deposits', 'medium_term_deposits', 'long_term_deposits', 'e_account', 'funds', \n",
    "    'mortgage', 'pensions', 'loans', 'taxes', 'credit_card', 'securities', 'home_account', \n",
    "    'payroll', 'pensions_payments', 'direct_debit'\n",
    "]\n",
    "\n",
    "# Drop the columns if they exist\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for machine learning, all columns are converted to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "CSV file successfully updated with new columns in renamed_reco_train.csv\n"
     ]
    }
   ],
   "source": [
    "date_columns = ['report_date', 'contract_start_date']  # Add any other date columns if necessary\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "# Calculate the difference in days\n",
    "df['contract_length'] = (df['report_date'] - df['contract_start_date']).dt.days\n",
    "\n",
    "# Insert 'contract_length' in the same spot as 'contract_start_date'\n",
    "start_date_index = df.columns.get_loc('contract_start_date')\n",
    "df.insert(start_date_index, 'contract_length', df.pop('contract_length'))\n",
    "\n",
    "# Drop the original 'contract_start_date' and 'report_date' columns\n",
    "df = df.drop(['contract_start_date', 'report_date', 'customer_id'], axis='columns')\n",
    "#replace missing values in gross income and age with median of distribution\n",
    "count = df['gross_income'].isna().sum()\n",
    "df['gross_income'] = df['gross_income'].fillna(df['gross_income'].median())\n",
    "df.head(10)\n",
    "age_new = df.iloc[:,3]\n",
    "print(len(age_new))\n",
    "age_new[1020:1040]\n",
    "new = []\n",
    "for i in age_new:\n",
    "    if i != ' NA':\n",
    "        new.append(int(i))\n",
    "\n",
    "med = median(new)\n",
    "med\n",
    "age = []\n",
    "for i in age_new:\n",
    "    if i !=' NA':\n",
    "        age.append(int(i))\n",
    "    else:\n",
    "        age.append(med)\n",
    "age[1020:1040]\n",
    "df['age'] = age\n",
    "\n",
    "df['country_residence'].unique()\n",
    "#has NA and many countries one hot encode\n",
    "count = df['country_residence'].isna().sum()\n",
    "#dropping row if column country_residenceis NA\n",
    "df = df.dropna(subset=[\"country_residence\"])\n",
    "len(df)\n",
    "df['gender'].unique()  \n",
    "# binary one hot encode\n",
    "df['new_customer_index'].unique() \n",
    "# binary one hot encode\n",
    "df['seniority_months'].unique() \n",
    "#conversion from string to int\n",
    "new = []\n",
    "for i in df['seniority_months']:\n",
    "    new.append(int(i))\n",
    "df['seniority_months'] = new\n",
    "\n",
    "df['customer_relation_type'].unique()\n",
    "# binary one hot encode\n",
    "df['residence_index'].unique()\n",
    "# binary one hot encode\n",
    "df['foreigner_index'].unique()\n",
    "# binary one hot encode\n",
    "df['join_channel'].unique()\n",
    "#one hot encoding for many variables\n",
    "df['deceased_index'].unique()\n",
    "# binary one hot encode\n",
    "df['province_name'].unique()\n",
    "#one hot encoding for many variables\n",
    "df['customer_segment'].unique()\n",
    "#one hot encoding for many variables\n",
    "df['employee_index'].unique()\n",
    "df = df.drop('employee_index', axis='columns')\n",
    "df = pd.get_dummies(df, columns=['customer_segment','province_name','join_channel','country_residence'], dtype = int)\n",
    "#one hot encoding for many variables\n",
    "df = pd.get_dummies(df, columns=['deceased_index','foreigner_index','residence_index','customer_relation_type','gender','new_customer_index' ], drop_first=True, dtype = int)\n",
    "# binary one hot encode\n",
    "df\n",
    "cols = df.columns.tolist()\n",
    "cols\n",
    "cols = cols[:5]+cols[9:] + cols[5:9]\n",
    "df = df[cols]\n",
    "# Move 'account' column to the last position\n",
    "account_column = df.pop('account')  # Remove the column and save it\n",
    "df['account'] = account_column\n",
    "\n",
    "# Save the updated DataFrame back to the renamed CSV file, overwriting it\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file successfully updated with new columns in {csv_file_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subgroupb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
