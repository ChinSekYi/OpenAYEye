{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns of the csv file to english readeable names, in addition the dataset used here is a subset of the original dataset, the original dataset train is 13,647,000 rows and test is 900,000 rows, loading it in will crash your computer. \n",
    "### Currently the train file in spanish is named sandenter_train_small and test is sandenter_test_small. The code uses sandenter_train_small as it has enough rows to do both train and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully relabelled and saved to renamed_reco_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating a new file to for the translated version, this is solely for visualisation purposes and is not used. \n",
    "# The original spanish verison will be used.\n",
    "\n",
    "csv_file_path = \"sandenter_train_small.csv\"  # input CSV file\n",
    "output_file_path = \"renamed_reco_train.csv\"  # output CSV file\n",
    "\n",
    "# Define the mapping of original Spanish column names to English column names\n",
    "column_mapping = {\n",
    "    \"fecha_dato\": \"report_date\",\n",
    "    \"ncodpers\": \"customer_id\",\n",
    "    \"ind_empleado\": \"employee_index\",\n",
    "    \"pais_residencia\": \"country_residence\",\n",
    "    \"sexo\": \"gender\",\n",
    "    \"age\": \"age\",\n",
    "    \"fecha_alta\": \"contract_start_date\",\n",
    "    \"ind_nuevo\": \"new_customer_index\",\n",
    "    \"antiguedad\": \"seniority_months\",\n",
    "    \"indrel\": \"primary_customer_status\",\n",
    "    \"ult_fec_cli_1t\": \"last_primary_customer_date\",\n",
    "    \"indrel_1mes\": \"customer_type_start_month\",\n",
    "    \"tiprel_1mes\": \"customer_relation_type\",\n",
    "    \"indresi\": \"residence_index\",\n",
    "    \"indext\": \"foreigner_index\",\n",
    "    \"conyuemp\": \"spouse_employee_index\",\n",
    "    \"canal_entrada\": \"join_channel\",\n",
    "    \"indfall\": \"deceased_index\",\n",
    "    \"tipodom\": \"address_type\",\n",
    "    \"cod_prov\": \"province_code\",\n",
    "    \"nomprov\": \"province_name\",\n",
    "    \"ind_actividad_cliente\": \"activity_index\",\n",
    "    \"renta\": \"gross_income\",\n",
    "    \"segmento\": \"customer_segment\",\n",
    "    \"ind_ahor_fin_ult1\": \"saving_account\",\n",
    "    \"ind_aval_fin_ult1\": \"guarantee\",\n",
    "    \"ind_cco_fin_ult1\": \"current_account\",\n",
    "    \"ind_cder_fin_ult1\": \"derivada_account\",\n",
    "    \"ind_cno_fin_ult1\": \"payroll_account\",\n",
    "    \"ind_ctju_fin_ult1\": \"junior_account\",\n",
    "    \"ind_ctma_fin_ult1\": \"more_particular_account\",\n",
    "    \"ind_ctop_fin_ult1\": \"particular_account\",\n",
    "    \"ind_ctpp_fin_ult1\": \"particular_plus_account\",\n",
    "    \"ind_deco_fin_ult1\": \"short_term_deposits\",\n",
    "    \"ind_deme_fin_ult1\": \"medium_term_deposits\",\n",
    "    \"ind_dela_fin_ult1\": \"long_term_deposits\",\n",
    "    \"ind_ecue_fin_ult1\": \"e_account\",\n",
    "    \"ind_fond_fin_ult1\": \"funds\",\n",
    "    \"ind_hip_fin_ult1\": \"mortgage\",\n",
    "    \"ind_plan_fin_ult1\": \"pensions\",\n",
    "    \"ind_pres_fin_ult1\": \"loans\",\n",
    "    \"ind_reca_fin_ult1\": \"taxes\",\n",
    "    \"ind_tjcr_fin_ult1\": \"credit_card\",\n",
    "    \"ind_valo_fin_ult1\": \"securities\",\n",
    "    \"ind_viv_fin_ult1\": \"home_account\",\n",
    "    \"ind_nomina_ult1\": \"payroll\",\n",
    "    \"ind_nom_pens_ult1\": \"pensions_payments\",\n",
    "    \"ind_recibo_ult1\": \"direct_debit\"\n",
    "}\n",
    "\n",
    "# Read the original CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#Drop the useless columns (correlation matrix used https://medium.com/@samarthjoelram/santander-recommendation-system-cab6b40596b5)\n",
    "# List of columns to drop if they exist\n",
    "columns_to_drop = ['ult_fec_cli_1t', 'ind_actividad_cliente', 'cod_prov', 'conyuemp', 'tipodom']\n",
    "# Drop columns if they exist in the DataFrame\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "# Rename the columns to english\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file successfully relabelled and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully updated with new columns in renamed_reco_train.csv\n"
     ]
    }
   ],
   "source": [
    "#Making changes to spanish datafile to suit our needs, the simplified dataset is the one we assume is collected by \n",
    "#companies.\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the renamed CSV file\n",
    "csv_file_path = \"renamed_reco_train.csv\"\n",
    "\n",
    "# Read the renamed CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define new column names\n",
    "fixed_deposits_col = 'fixed_deposits'\n",
    "loan_col = 'loan'\n",
    "credit_card_debit_card_col = 'credit_card_debit_card'\n",
    "account_col = 'account'\n",
    "\n",
    "# Check and create a new column for fixed deposits, if it doesn't exist\n",
    "if fixed_deposits_col not in df.columns:\n",
    "    deposit_columns = [\n",
    "        \"short_term_deposits\",  # ind_deco_fin_ult1\n",
    "        \"medium_term_deposits\",  # ind_deme_fin_ult1\n",
    "        \"long_term_deposits\"    # ind_dela_fin_ult1\n",
    "    ]\n",
    "    df[fixed_deposits_col] = df[deposit_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for loans, if it doesn't exist\n",
    "if loan_col not in df.columns:\n",
    "    loan_columns = [\n",
    "        \"loans\",                # ind_pres_fin_ult1\n",
    "        \"pensions\"             # ind_plan_fin_ult1\n",
    "    ]\n",
    "    df[loan_col] = df[loan_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for credit and debit cards, if it doesn't exist\n",
    "if credit_card_debit_card_col not in df.columns:\n",
    "    credit_card_columns = [\n",
    "        \"credit_card\",         # ind_tjcr_fin_ult1\n",
    "        \"direct_debit\"        # ind_recibo_ult1\n",
    "    ]\n",
    "    df[credit_card_debit_card_col] = df[credit_card_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for all accounts combined, if it doesn't exist\n",
    "if account_col not in df.columns:\n",
    "    account_columns = [\n",
    "        \"saving_account\",      # ind_ahor_fin_ult1\n",
    "        \"current_account\",     # ind_cco_fin_ult1\n",
    "        \"derivada_account\",    # ind_cder_fin_ult1\n",
    "        \"payroll_account\",     # ind_cno_fin_ult1\n",
    "        \"junior_account\",      # ind_ctju_fin_ult1\n",
    "        \"more_particular_account\",  # ind_ctma_fin_ult1\n",
    "        \"particular_account\",   # ind_ctop_fin_ult1\n",
    "        \"particular_plus_account\", # ind_ctpp_fin_ult1\n",
    "        \"e_account\",           # ind_ecue_fin_ult1\n",
    "        \"funds\",               # ind_fond_fin_ult1\n",
    "        \"home_account\",        # ind_viv_fin_ult1\n",
    "    ]\n",
    "    df[account_col] = df[account_columns].any(axis=1).astype(int)\n",
    "    \n",
    "# List of columns to drop, we merged these columns for to keep it simple to present \n",
    "# The model used for commercial purposes does not merge the products together\n",
    "columns_to_drop = [\n",
    "    'saving_account', 'guarantee', 'current_account', 'derivada_account', 'payroll_account', \n",
    "    'junior_account', 'more_particular_account', 'particular_account', 'particular_plus_account', \n",
    "    'short_term_deposits', 'medium_term_deposits', 'long_term_deposits', 'e_account', 'funds', \n",
    "    'mortgage', 'pensions', 'loans', 'taxes', 'credit_card', 'securities', 'home_account', \n",
    "    'payroll', 'pensions_payments', 'direct_debit'\n",
    "]\n",
    "\n",
    "# Drop the columns if they exist\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "\n",
    "# Save the updated DataFrame back to the renamed CSV file, overwriting it\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file successfully updated with new columns in {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data (making sure columns with dates are date columns) and implement the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('renamed_reco_train.csv')\n",
    "\n",
    "# Convert date columns to datetime\n",
    "date_columns = ['report_date', 'contract_start_date']  # Add any other date columns if necessary\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "# List of columns to convert to categorical\n",
    "columns_to_convert = [\n",
    "    'employee_index', 'gender', 'customer_relation_type', 'residence_index', \n",
    "    'foreigner_index', 'join_channel', 'deceased_index', 'province_name', 'customer_segment'\n",
    "]\n",
    "# Convert specified columns to categorical\n",
    "df[columns_to_convert] = df[columns_to_convert].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use whatever model you want here. The dataset name is \"df\". Note that the dataset includes datetime columns and categorical columns, get rid of them if they are not applicable to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any model that can produce a probability would be better, the most obvious candidate is logistic regression       but it has limitations like needing to be retrained everytime new data rows are added. Online learning and       variants of logistic regression do exist to allow the model to be more adaptable to new data.\n"
     ]
    }
   ],
   "source": [
    "print(\"Any model that can produce a probability would be better, the most obvious candidate is logistic regression \\\n",
    "      but it has limitations like needing to be retrained everytime new data rows are added. Online learning and \\\n",
    "      variants of logistic regression do exist to allow the model to be more adaptable to new data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subgroupb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
