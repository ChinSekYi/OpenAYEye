{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This ipynb file is WIP, and might need to be part of the pipeline, its purpose is to scan the the big boy file to get enough minority classes combined with SMOTE to get a dataset that is not too imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "file_path = \"normal.csv\"  # Replace with your file path\n",
    "column_name = \"your_column\"   # Replace with the column you're filtering on\n",
    "value = True                  # The value to filter on (e.g., True)\n",
    "\n",
    "# Read CSV in chunks to avoid memory issues\n",
    "chunksize = 100000  # Adjust this if needed for larger files\n",
    "filtered_rows = []\n",
    "\n",
    "# Define the mapping of original Spanish column names to English column names\n",
    "column_mapping = {\n",
    "    \"fecha_dato\": \"report_date\",\n",
    "    \"ncodpers\": \"customer_id\",\n",
    "    \"ind_empleado\": \"employee_index\",\n",
    "    \"pais_residencia\": \"country_residence\",\n",
    "    \"sexo\": \"gender\",\n",
    "    \"age\": \"age\",\n",
    "    \"fecha_alta\": \"contract_start_date\",\n",
    "    \"ind_nuevo\": \"new_customer_index\",\n",
    "    \"antiguedad\": \"seniority_months\",\n",
    "    \"indrel\": \"primary_customer_status\",\n",
    "    \"ult_fec_cli_1t\": \"last_primary_customer_date\",\n",
    "    \"indrel_1mes\": \"customer_type_start_month\",\n",
    "    \"tiprel_1mes\": \"customer_relation_type\",\n",
    "    \"indresi\": \"residence_index\",\n",
    "    \"indext\": \"foreigner_index\",\n",
    "    \"conyuemp\": \"spouse_employee_index\",\n",
    "    \"canal_entrada\": \"join_channel\",\n",
    "    \"indfall\": \"deceased_index\",\n",
    "    \"tipodom\": \"address_type\",\n",
    "    \"cod_prov\": \"province_code\",\n",
    "    \"nomprov\": \"province_name\",\n",
    "    \"ind_actividad_cliente\": \"activity_index\",\n",
    "    \"renta\": \"gross_income\",\n",
    "    \"segmento\": \"customer_segment\",\n",
    "    \"ind_ahor_fin_ult1\": \"saving_account\",\n",
    "    \"ind_aval_fin_ult1\": \"guarantee\",\n",
    "    \"ind_cco_fin_ult1\": \"current_account\",\n",
    "    \"ind_cder_fin_ult1\": \"derivada_account\",\n",
    "    \"ind_cno_fin_ult1\": \"payroll_account\",\n",
    "    \"ind_ctju_fin_ult1\": \"junior_account\",\n",
    "    \"ind_ctma_fin_ult1\": \"more_particular_account\",\n",
    "    \"ind_ctop_fin_ult1\": \"particular_account\",\n",
    "    \"ind_ctpp_fin_ult1\": \"particular_plus_account\",\n",
    "    \"ind_deco_fin_ult1\": \"short_term_deposits\",\n",
    "    \"ind_deme_fin_ult1\": \"medium_term_deposits\",\n",
    "    \"ind_dela_fin_ult1\": \"long_term_deposits\",\n",
    "    \"ind_ecue_fin_ult1\": \"e_account\",\n",
    "    \"ind_fond_fin_ult1\": \"funds\",\n",
    "    \"ind_hip_fin_ult1\": \"mortgage\",\n",
    "    \"ind_plan_fin_ult1\": \"pensions\",\n",
    "    \"ind_pres_fin_ult1\": \"loans\",\n",
    "    \"ind_reca_fin_ult1\": \"taxes\",\n",
    "    \"ind_tjcr_fin_ult1\": \"credit_card\",\n",
    "    \"ind_valo_fin_ult1\": \"securities\",\n",
    "    \"ind_viv_fin_ult1\": \"home_account\",\n",
    "    \"ind_nomina_ult1\": \"payroll\",\n",
    "    \"ind_nom_pens_ult1\": \"pensions_payments\",\n",
    "    \"ind_recibo_ult1\": \"direct_debit\"\n",
    "}\n",
    "\n",
    "# Iterate through the file in chunks\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "    # Filter rows where the column equals the desired value\n",
    "    matching_rows = chunk[chunk[column_name] == value]\n",
    "    filtered_rows.append(matching_rows)\n",
    "    # Rename the columns to english\n",
    "    chunk.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Define new column names\n",
    "fixed_deposits_col = 'fixed_deposits'\n",
    "loan_col = 'loan'\n",
    "credit_card_debit_card_col = 'credit_card_debit_card'\n",
    "account_col = 'account'\n",
    "\n",
    "# Check and create a new column for fixed deposits, if it doesn't exist\n",
    "if fixed_deposits_col not in df.columns:\n",
    "    deposit_columns = [\n",
    "        \"short_term_deposits\",  # ind_deco_fin_ult1\n",
    "        \"medium_term_deposits\",  # ind_deme_fin_ult1\n",
    "        \"long_term_deposits\"    # ind_dela_fin_ult1\n",
    "    ]\n",
    "    df[fixed_deposits_col] = df[deposit_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for loans, if it doesn't exist\n",
    "if loan_col not in df.columns:\n",
    "    loan_columns = [\n",
    "        \"loans\",                # ind_pres_fin_ult1\n",
    "        \"pensions\"             # ind_plan_fin_ult1\n",
    "    ]\n",
    "    df[loan_col] = df[loan_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for credit and debit cards, if it doesn't exist\n",
    "if credit_card_debit_card_col not in df.columns:\n",
    "    credit_card_columns = [\n",
    "        \"credit_card\",         # ind_tjcr_fin_ult1\n",
    "        \"direct_debit\"        # ind_recibo_ult1\n",
    "    ]\n",
    "    df[credit_card_debit_card_col] = df[credit_card_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Check and create a new column for all accounts combined, if it doesn't exist\n",
    "if account_col not in df.columns:\n",
    "    account_columns = [\n",
    "        \"saving_account\",      # ind_ahor_fin_ult1\n",
    "        \"current_account\",     # ind_cco_fin_ult1\n",
    "        \"derivada_account\",    # ind_cder_fin_ult1\n",
    "        \"payroll_account\",     # ind_cno_fin_ult1\n",
    "        \"junior_account\",      # ind_ctju_fin_ult1\n",
    "        \"more_particular_account\",  # ind_ctma_fin_ult1\n",
    "        \"particular_account\",   # ind_ctop_fin_ult1\n",
    "        \"particular_plus_account\", # ind_ctpp_fin_ult1\n",
    "        \"e_account\",           # ind_ecue_fin_ult1\n",
    "        \"funds\",               # ind_fond_fin_ult1\n",
    "        \"home_account\",        # ind_viv_fin_ult1\n",
    "    ]\n",
    "    df[account_col] = df[account_columns].any(axis=1).astype(int)\n",
    "    \n",
    "    # List of columns to drop, we merged these columns for to keep it simple to present \n",
    "    # The model used for commercial purposes does not merge the products together\n",
    "    columns_to_drop = [\n",
    "        'saving_account', 'guarantee', 'current_account', 'derivada_account', 'payroll_account', \n",
    "        'junior_account', 'more_particular_account', 'particular_account', 'particular_plus_account', \n",
    "        'short_term_deposits', 'medium_term_deposits', 'long_term_deposits', 'e_account', 'funds', \n",
    "        'mortgage', 'pensions', 'loans', 'taxes', 'credit_card', 'securities', 'home_account', \n",
    "         'payroll', 'pensions_payments', 'direct_debit'\n",
    "    ]\n",
    "\n",
    "    # Drop the columns if they exist\n",
    "    df = chunk.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    # Stop if we have enough rows\n",
    "if sum(len(rows) for rows in filtered_rows) >= 5000:\n",
    "    break\n",
    "\n",
    "# Combine filtered chunks into one DataFrame\n",
    "result = pd.concat(filtered_rows).head(5000)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result.to_csv(\"subset.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {len(result)} rows to 'subset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution for 'fixed_deposits':\n",
      "fixed_deposits\n",
      "0    9879\n",
      "1      67\n",
      "Name: count, dtype: int64\n",
      "fixed_deposits\n",
      "0    99.326362\n",
      "1     0.673638\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution for 'loan':\n",
      "loan\n",
      "0    9938\n",
      "1       8\n",
      "Name: count, dtype: int64\n",
      "loan\n",
      "0    99.919566\n",
      "1     0.080434\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution for 'credit_card_debit_card':\n",
      "credit_card_debit_card\n",
      "0    9266\n",
      "1     680\n",
      "Name: count, dtype: int64\n",
      "credit_card_debit_card\n",
      "0    93.163081\n",
      "1     6.836919\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution for 'account':\n",
      "account\n",
      "1    9850\n",
      "0      96\n",
      "Name: count, dtype: int64\n",
      "account\n",
      "1    99.034788\n",
      "0     0.965212\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"cleaned_covid.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select the last 4 columns\n",
    "last_4_columns = df.iloc[:, -4:]\n",
    "\n",
    "# Display class distribution for each of the last 4 columns\n",
    "for column in last_4_columns.columns:\n",
    "    print(f\"\\nClass distribution for '{column}':\")\n",
    "    print(last_4_columns[column].value_counts())\n",
    "    print(last_4_columns[column].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Optional: Save the distribution to a CSV file\n",
    "distribution = last_4_columns.apply(lambda x: x.value_counts())\n",
    "distribution.to_csv(\"class_imbalance_counts.csv\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa3101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
