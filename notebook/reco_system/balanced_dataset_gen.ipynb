{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This ipynb file is WIP, and might need to be part of the pipeline, its purpose is to scan the the big boy file to get enough minority classes combined with SMOTE to get a dataset that is not too imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "file_path = \"normal.csv\"  # Replace with your file path\n",
    "finished =  \"reco.csv\"\n",
    "column_name = \"your_column\"  # Replace with the column you're filtering on\n",
    "value = True  # The value to filter on (e.g., True)\n",
    "\n",
    "# Read CSV in chunks to avoid memory issues\n",
    "chunksize = 100000  # Adjust this if needed for larger files\n",
    "filtered_rows = []\n",
    "\n",
    "# Define the mapping of original Spanish column names to English column names\n",
    "column_mapping = {\n",
    "    \"fecha_dato\": \"report_date\",\n",
    "    \"ncodpers\": \"customer_id\",\n",
    "    \"ind_empleado\": \"employee_index\",\n",
    "    \"pais_residencia\": \"country_residence\",\n",
    "    \"sexo\": \"gender\",\n",
    "    \"age\": \"age\",\n",
    "    \"fecha_alta\": \"contract_start_date\",\n",
    "    \"ind_nuevo\": \"new_customer_index\",\n",
    "    \"antiguedad\": \"seniority_months\",\n",
    "    \"indrel\": \"primary_customer_status\",\n",
    "    \"ult_fec_cli_1t\": \"last_primary_customer_date\",\n",
    "    \"indrel_1mes\": \"customer_type_start_month\",\n",
    "    \"tiprel_1mes\": \"customer_relation_type\",\n",
    "    \"indresi\": \"residence_index\",\n",
    "    \"indext\": \"foreigner_index\",\n",
    "    \"conyuemp\": \"spouse_employee_index\",\n",
    "    \"canal_entrada\": \"join_channel\",\n",
    "    \"indfall\": \"deceased_index\",\n",
    "    \"tipodom\": \"address_type\",\n",
    "    \"cod_prov\": \"province_code\",\n",
    "    \"nomprov\": \"province_name\",\n",
    "    \"ind_actividad_cliente\": \"activity_index\",\n",
    "    \"renta\": \"gross_income\",\n",
    "    \"segmento\": \"customer_segment\",\n",
    "    \"ind_ahor_fin_ult1\": \"saving_account\",\n",
    "    \"ind_aval_fin_ult1\": \"guarantee\",\n",
    "    \"ind_cco_fin_ult1\": \"current_account\",\n",
    "    \"ind_cder_fin_ult1\": \"derivada_account\",\n",
    "    \"ind_cno_fin_ult1\": \"payroll_account\",\n",
    "    \"ind_ctju_fin_ult1\": \"junior_account\",\n",
    "    \"ind_ctma_fin_ult1\": \"more_particular_account\",\n",
    "    \"ind_ctop_fin_ult1\": \"particular_account\",\n",
    "    \"ind_ctpp_fin_ult1\": \"particular_plus_account\",\n",
    "    \"ind_deco_fin_ult1\": \"short_term_deposits\",\n",
    "    \"ind_deme_fin_ult1\": \"medium_term_deposits\",\n",
    "    \"ind_dela_fin_ult1\": \"long_term_deposits\",\n",
    "    \"ind_ecue_fin_ult1\": \"e_account\",\n",
    "    \"ind_fond_fin_ult1\": \"funds\",\n",
    "    \"ind_hip_fin_ult1\": \"mortgage\",\n",
    "    \"ind_plan_fin_ult1\": \"pensions\",\n",
    "    \"ind_pres_fin_ult1\": \"loans\",\n",
    "    \"ind_reca_fin_ult1\": \"taxes\",\n",
    "    \"ind_tjcr_fin_ult1\": \"credit_card\",\n",
    "    \"ind_valo_fin_ult1\": \"securities\",\n",
    "    \"ind_viv_fin_ult1\": \"home_account\",\n",
    "    \"ind_nomina_ult1\": \"payroll\",\n",
    "    \"ind_nom_pens_ult1\": \"pensions_payments\",\n",
    "    \"ind_recibo_ult1\": \"direct_debit\"\n",
    "}\n",
    "\n",
    "# Iterate through the file in chunks\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "    # Rename the columns to English\n",
    "    chunk.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "    # Create fixed deposits column if not present\n",
    "    if 'fixed_deposits' not in chunk.columns:\n",
    "        deposit_columns = [\n",
    "            \"short_term_deposits\", \"medium_term_deposits\", \"long_term_deposits\"\n",
    "        ]\n",
    "        chunk['fixed_deposits'] = chunk[deposit_columns].any(axis=1).astype(int)\n",
    "\n",
    "    # Create loans column if not present\n",
    "    if 'loan' not in chunk.columns:\n",
    "        loan_columns = [\"loans\", \"pensions\"]\n",
    "        chunk['loan'] = chunk[loan_columns].any(axis=1).astype(int)\n",
    "\n",
    "    # Create credit_card_debit_card column if not present\n",
    "    if 'credit_card_debit_card' not in chunk.columns:\n",
    "        credit_card_columns = [\"credit_card\", \"direct_debit\"]\n",
    "        chunk['credit_card_debit_card'] = chunk[credit_card_columns].any(axis=1).astype(int)\n",
    "\n",
    "    # Create account column if not present\n",
    "    if 'account' not in chunk.columns:\n",
    "        account_columns = [\n",
    "            \"saving_account\", \"current_account\", \"derivada_account\", \"payroll_account\",\n",
    "            \"junior_account\", \"more_particular_account\", \"particular_account\",\n",
    "            \"particular_plus_account\", \"e_account\", \"funds\", \"home_account\"\n",
    "        ]\n",
    "        chunk['account'] = chunk[account_columns].any(axis=1).astype(int)\n",
    "\n",
    "    # List of columns to drop\n",
    "    columns_to_drop = [\n",
    "        'saving_account', 'guarantee', 'current_account', 'derivada_account', 'payroll_account',\n",
    "        'junior_account', 'more_particular_account', 'particular_account', 'particular_plus_account',\n",
    "        'short_term_deposits', 'medium_term_deposits', 'long_term_deposits', 'e_account', 'funds',\n",
    "        'mortgage', 'pensions', 'loans', 'taxes', 'credit_card', 'securities', 'home_account',\n",
    "        'payroll', 'pensions_payments', 'direct_debit'\n",
    "    ]\n",
    "\n",
    "    # Drop the merged columns if they exist\n",
    "    chunk.drop(columns=[col for col in columns_to_drop if col in chunk.columns], inplace=True)\n",
    "    # Filter rows where the column equals the desired value\n",
    "    matching_rows = chunk[chunk[column_name] == value]\n",
    "    filtered_rows.append(matching_rows)\n",
    "    \n",
    "    # Stop if we have enough rows\n",
    "    if sum(len(rows) for rows in filtered_rows) >= 5000:\n",
    "        break\n",
    "\n",
    "# Combine filtered chunks into one DataFrame\n",
    "result = pd.concat(filtered_rows).head(5000)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result.to_csv(finished, index=False)\n",
    "\n",
    "print(f\"Saved {len(result)} rows\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution for 'fixed_deposits':\n",
      "fixed_deposits\n",
      "0    9879\n",
      "1      67\n",
      "Name: count, dtype: int64\n",
      "fixed_deposits\n",
      "0    99.326362\n",
      "1     0.673638\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution for 'loan':\n",
      "loan\n",
      "0    9938\n",
      "1       8\n",
      "Name: count, dtype: int64\n",
      "loan\n",
      "0    99.919566\n",
      "1     0.080434\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution for 'credit_card_debit_card':\n",
      "credit_card_debit_card\n",
      "0    9266\n",
      "1     680\n",
      "Name: count, dtype: int64\n",
      "credit_card_debit_card\n",
      "0    93.163081\n",
      "1     6.836919\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution for 'account':\n",
      "account\n",
      "1    9850\n",
      "0      96\n",
      "Name: count, dtype: int64\n",
      "account\n",
      "1    99.034788\n",
      "0     0.965212\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"cleaned_covid.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select the last 4 columns\n",
    "last_4_columns = df.iloc[:, -4:]\n",
    "\n",
    "# Display class distribution for each of the last 4 columns\n",
    "for column in last_4_columns.columns:\n",
    "    print(f\"\\nClass distribution for '{column}':\")\n",
    "    print(last_4_columns[column].value_counts())\n",
    "    print(last_4_columns[column].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Optional: Save the distribution to a CSV file\n",
    "distribution = last_4_columns.apply(lambda x: x.value_counts())\n",
    "distribution.to_csv(\"class_imbalance_counts.csv\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa3101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
