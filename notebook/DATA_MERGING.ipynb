{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/bank-full.csv\", sep = \";\", header = 0) #from UCI\n",
    "df2 = pd.read_csv(\"data/TotalLoanstoNonBankCustomersbyType.csv\") #from data.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['CustomerID'] = df1.index\n",
    "df1 = df1.rename(columns={'y': 'subscribed_to_term_deposit'})\n",
    "\n",
    "df2_filtered = df2[df2['level_1'] == 'Consumer']\n",
    "df2_subset = df2_filtered[['level_2', 'total_loans']]\n",
    "df2_subset = df2_subset.rename(columns={'level_2': 'loan_category'})\n",
    "\n",
    "merged_df = pd.concat([df1, df2_subset], axis=1)\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate numerical_columns and categorical_columns, as we'll be dealing with missing data in them differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['CustomerID','age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing','loan', 'contact', 'day','month', 'poutcome', 'total_loans','loan_category', 'subscribed_to_term_deposit']\n",
    "all_columns = numerical_columns + categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing data\n",
    "Use different techniques to \"fill in missing data\"   \n",
    "Imputers will generate synthetic data based on existing features and use it to fill up the empty cells.\n",
    "Below, I used IterativeImputer for numerical data and SimpleImputer(\"most_frequent\") for categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", IterativeImputer(random_state=0)), # Iterative imputation for numerical data\n",
    "                    (\"scaler\", MinMaxScaler()), # Scaling numerical data\n",
    "                ]\n",
    "            )\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Impute missing categorical data\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num_pipeline\", num_pipeline, numerical_columns),\n",
    "                    (\"cat_pipeline\", cat_pipeline, categorical_columns),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Apply transformation on dataset\n",
    "processed_data = preprocessor.fit_transform(merged_df)\n",
    "\n",
    "# Convert processed_data back to a DataFrame\n",
    "processed_df = pd.DataFrame(processed_data, columns=all_columns)\n",
    "\n",
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged_df.shape should equal to processed_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
