{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confluence Documentation: https://openayeye.atlassian.net/wiki/x/AYAs\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Merging 1](#Merging-1)\n",
    "    1. [Filling in missing data](#Filling-in-missing-data)\n",
    "    2. [Check if distribution is preserved](#Check-if-distribution-is-preserved)\n",
    "2. [Merging 2](#Merging-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/bank-full.csv\", sep = \";\", header = 0) #from UCI Bank Marketing\n",
    "df2 = pd.read_csv(\"data/Churn_Modelling.csv\").iloc[:, 3:] #from data.gov Total Loans to Non-Bank Customers by Type\n",
    "# df1\n",
    "\n",
    "df1.rename({i:i.lower() for i in df2.columns.values}, axis=1, inplace=True)\n",
    "df2.rename({i:i.lower() for i in df2.columns.values}, axis=1, inplace=True)\n",
    "\n",
    "dtype_dict = pd.DataFrame(pd.concat([df1.dtypes, (df2.dtypes)], axis=0))\n",
    "dtype_dict = dtype_dict.T.loc[:, ~dtype_dict.T.columns.duplicated()].T.copy().iloc[:, 0]\n",
    "# dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Dataframes\n",
    "merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "# print(merged_df['isactivemember'])\n",
    "\n",
    "# Find numerical & categorical columns\n",
    "which_object = [i == np.dtype('O') for i in merged_df.dtypes]\n",
    "categorical_columns = merged_df.columns[which_object].values\n",
    "numerical_columns = merged_df.columns[np.invert(which_object)].values\n",
    "all_columns = np.concatenate([numerical_columns, categorical_columns])\n",
    "\n",
    "# Rearrange column sequence\n",
    "merged_df = merged_df.loc[:, all_columns]\n",
    "merged_df.reset_index(drop=True)\n",
    "merged_df[categorical_columns] = merged_df.loc[:, categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
       "       'creditscore', 'tenure', 'numofproducts', 'estimatedsalary', 'job',\n",
       "       'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
       "       'month', 'poutcome', 'subscribed', 'surname', 'geography', 'gender',\n",
       "       'hascrcard', 'isactivemember', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dtypes = merged_df.dtypes[categorical_columns]\n",
    "num_dtypes = dtype_dict[numerical_columns]\n",
    "dtype_dict = dict(cat_dtypes) |  dict(num_dtypes)\n",
    "dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[:, categorical_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[:, numerical_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate numerical_columns and categorical_columns, as we'll be dealing with missing data in them differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing data\n",
    "Use different techniques to \"fill in missing data\"   \n",
    "Imputers will generate synthetic data based on existing features and use it to fill up the empty cells.\n",
    "Below, I used IterativeImputer for numerical data and SimpleImputer(\"most_frequent\") for categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", IterativeImputer(random_state=0)), # (Multivariate Imputation)\n",
    "                    # Some examples of other imputation methods:\n",
    "                    #   (\"imputer\", SimpleImputer(strategy='mean')), \n",
    "                    #   (\"imputer\", SimpleImputer(strategy='median')), \n",
    "                    #   (\"imputer\", SimpleImputer(strategy='most_frequent')), \n",
    "                    # (\"scaler\", MinMaxScaler()), # Scaling numerical data\n",
    "                ]\n",
    "            )\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        # Some examples of other imputation methods:\n",
    "        # (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),  \n",
    "        # (\"imputer\", KNNImputer(n_neighbors=5, weights=\"uniform\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num_pipeline\", num_pipeline, numerical_columns),\n",
    "                    (\"cat_pipeline\", cat_pipeline, categorical_columns),\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformation on dataset\n",
    "processed_data = preprocessor.fit_transform(merged_df)\n",
    "\n",
    "# Convert processed_data back to a DataFrame\n",
    "processed_df = pd.DataFrame(processed_data, columns=all_columns)\n",
    "\n",
    "# Convert numerical columns back to float\n",
    "processed_df.loc[:, numerical_columns] = processed_df[numerical_columns].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "processed_df = processed_df.astype(dtype_dict)\n",
    "# print(processed_df.shape, merged_df.shape)\n",
    "# print(processed_df.head())\n",
    "feat_cols = [i for i in processed_df.columns if (i != 'subscribed' and i != 'exited')]\n",
    "feat_cols\n",
    "label_sub = ['subscribed']\n",
    "# label_exit = ['exited']\n",
    "X = processed_df[feat_cols]\n",
    "y = processed_df[label_sub]\n",
    "X.head(), y.head()\n",
    "# processed_df.to_csv(\"data/merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged_df.shape should equal to processed_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if distribution is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eg. Kolmogorov-Smirnov Test for Numerical Columns\n",
    "#### Interpretation  \n",
    "- **KS Statistic**: A KS statistic of 0.0 indicates that there is no difference between the distributions of the original and processed data for each column.  \n",
    "- **P-value**: A p-value of 1.0 means that the test results are consistent with the null hypothesis, which states that the distributions of the two datasets are the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Kolmogorov-Smirnov test to check if two distributions are the same\n",
    "\n",
    "def ks_test_column(original_column, processed_column):\n",
    "    # Drop any missing values from original column\n",
    "    original_non_missing = original_column.dropna()\n",
    "    # Kolmogorov-Smirnov test\n",
    "    ks_stat, p_value = ks_2samp(original_non_missing, processed_column)\n",
    "    print(f\"Kolmogorov-Smirnov test for \\033[96m{original_column.name}\\033[00m:\")\n",
    "    print(f\"KS Statistic: {ks_stat}, p-value: {p_value:.3f}\")\n",
    "    return ks_stat, p_value\n",
    "\n",
    "# Apply the KS test to all numerical columns\n",
    "for col in numerical_columns:\n",
    "    ks_test_column(merged_df[col], processed_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary  \n",
    "The KS test results suggest that the transformations applied to the numerical columns in your dataset did not alter their distributions. This outcome implies that the preprocessing steps (including scaling or imputation) did not change the fundamental distribution of the data in each column. Therefore, the original and processed data distributions are effectively identical for these columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Test for Categorical Columns\n",
    "\n",
    "#### Interpretation\n",
    "- **Chi-Square Statistic**: Measures the magnitude of the difference between observed and expected frequencies. A higher value indicates a greater difference.    \n",
    "- **P-value**: Indicates the probability of observing the data if the null hypothesis (that the distributions are the same) is true. A low p-value (typically < 0.05) suggests that there is a significant difference between the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import chi2_contingency\n",
    "\n",
    "# def chi2_test_column(original_column, processed_column):\n",
    "#     # Create contingency table\n",
    "#     contingency_table = pd.crosstab(original_column, processed_column)\n",
    "    \n",
    "#     # Perform Chi-Square Test\n",
    "#     chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    \n",
    "#     print(f\"Chi-Square test for \\033[96m{original_column.name}\\033[00m:\")\n",
    "#     print(f\"Chi-Square Statistic: {chi2_stat}, p-value: {p_value:.3f}\")\n",
    "#     return chi2_stat, p_value\n",
    "\n",
    "# # Apply the Chi-Square test to all categorical columns\n",
    "# for col in categorical_columns:\n",
    "#     chi2_test_column(merged_df[col], processed_df[col])\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "print(pd.concat([merged_df['job'].value_counts(), processed_df['job'].value_counts()], axis=1))\n",
    "chisquare(merged_df['job'].value_counts(), processed_df['job'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**  \n",
    "Since all p-values are 0.000, there are significant differences between the observed and expected distributions for each categorical column. \n",
    "This suggests that the transformations or imputations performed have significantly altered the distributions from their original state.\n",
    "\n",
    "<font color='red'>Hence.....we need to find better imputation methods for categorical columns!!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 2\n",
    ".... continueeeee "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
