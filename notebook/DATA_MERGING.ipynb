{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/bank-full.csv\", sep = \";\", header = 0) #from UCI Bank Marketing\n",
    "df2 = pd.read_csv(\"data/TotalLoanstoNonBankCustomersbyType.csv\") #from data.gov Total Loans to Non-Bank Customers by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.insert(0, 'CustomerID', df1.index)\n",
    "df1 = df1.rename(columns={'y': 'subscribed_to_term_deposit'})\n",
    "\n",
    "df2_filtered = df2[df2['level_1'] == 'Consumer']\n",
    "df2_subset = df2_filtered[['level_2', 'total_loans']]\n",
    "df2_subset = df2_subset.rename(columns={'level_2': 'loan_category'})\n",
    "\n",
    "merged_df = pd.concat([df1, df2_subset], axis=1)\n",
    "merged_df.shape\n",
    "#df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate numerical_columns and categorical_columns, as we'll be dealing with missing data in them differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['CustomerID','age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing','loan', 'contact', 'day','month', 'poutcome', 'total_loans','loan_category', 'subscribed_to_term_deposit']\n",
    "all_columns = numerical_columns + categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing data\n",
    "Use different techniques to \"fill in missing data\"   \n",
    "Imputers will generate synthetic data based on existing features and use it to fill up the empty cells.\n",
    "Below, I used IterativeImputer for numerical data and SimpleImputer(\"most_frequent\") for categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", IterativeImputer(random_state=0)), # (Multivariate Imputation)\n",
    "                    # Some examples of other imputation methods:\n",
    "                    #   (\"imputer\", SimpleImputer(strategy='mean')), \n",
    "                    #   (\"imputer\", SimpleImputer(strategy='median')), \n",
    "                    #   (\"imputer\", SimpleImputer(strategy='most_frequent')), \n",
    "                    (\"scaler\", MinMaxScaler()), # Scaling numerical data\n",
    "                ]\n",
    "            )\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Impute missing categorical data\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>total_loans</th>\n",
       "      <th>loan_category</th>\n",
       "      <th>subscribed_to_term_deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>0.053070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1099.7</td>\n",
       "      <td>Housing and Bridging Loans</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.073067</td>\n",
       "      <td>0.030704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1099.7</td>\n",
       "      <td>Housing and Bridging Loans</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.072822</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1099.7</td>\n",
       "      <td>Housing and Bridging Loans</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.086476</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1099.7</td>\n",
       "      <td>Housing and Bridging Loans</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1099.7</td>\n",
       "      <td>Housing and Bridging Loans</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID       age   balance  duration  campaign  pdays  previous  \\\n",
       "0    0.000000  0.519481  0.092259  0.053070       0.0    0.0       0.0   \n",
       "1    0.000022  0.337662  0.073067  0.030704       0.0    0.0       0.0   \n",
       "2    0.000044  0.194805  0.072822  0.015453       0.0    0.0       0.0   \n",
       "3    0.000066  0.376623  0.086476  0.018707       0.0    0.0       0.0   \n",
       "4    0.000088  0.194805  0.072812  0.040260       0.0    0.0       0.0   \n",
       "\n",
       "            job  marital  education default housing loan  contact day month  \\\n",
       "0    management  married   tertiary      no     yes   no  unknown   5   may   \n",
       "1    technician   single  secondary      no     yes   no  unknown   5   may   \n",
       "2  entrepreneur  married  secondary      no     yes  yes  unknown   5   may   \n",
       "3   blue-collar  married    unknown      no     yes   no  unknown   5   may   \n",
       "4       unknown   single    unknown      no      no   no  unknown   5   may   \n",
       "\n",
       "  poutcome total_loans               loan_category subscribed_to_term_deposit  \n",
       "0  unknown      1099.7  Housing and Bridging Loans                         no  \n",
       "1  unknown      1099.7  Housing and Bridging Loans                         no  \n",
       "2  unknown      1099.7  Housing and Bridging Loans                         no  \n",
       "3  unknown      1099.7  Housing and Bridging Loans                         no  \n",
       "4  unknown      1099.7  Housing and Bridging Loans                         no  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num_pipeline\", num_pipeline, numerical_columns),\n",
    "                    (\"cat_pipeline\", cat_pipeline, categorical_columns),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Apply transformation on dataset\n",
    "processed_data = preprocessor.fit_transform(merged_df)\n",
    "\n",
    "# Convert processed_data back to a DataFrame\n",
    "processed_df = pd.DataFrame(processed_data, columns=all_columns)\n",
    "\n",
    "# Convert numerical columns back to float\n",
    "processed_df[numerical_columns] = processed_df[numerical_columns].apply(pd.to_numeric)\n",
    "\n",
    "processed_df.shape\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged_df.shape should equal to processed_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if distribution is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eg. Kolmogorov-Smirnov Test for Numerical Columns\n",
    "#### Interpretation  \n",
    "- **KS Statistic**: A KS statistic of 0.0 indicates that there is no difference between the distributions of the original and processed data for each column.  \n",
    "- **P-value**: A p-value of 1.0 means that the test results are consistent with the null hypothesis, which states that the distributions of the two datasets are the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov test for \u001b[96mCustomerID\u001b[00m:\n",
      "KS Statistic: 0.9999557629780363, p-value: 0.0\n",
      "Kolmogorov-Smirnov test for \u001b[96mage\u001b[00m:\n",
      "KS Statistic: 1.0, p-value: 0.0\n",
      "Kolmogorov-Smirnov test for \u001b[96mbalance\u001b[00m:\n",
      "KS Statistic: 0.8389551215412178, p-value: 0.0\n",
      "Kolmogorov-Smirnov test for \u001b[96mduration\u001b[00m:\n",
      "KS Statistic: 0.9999115259560726, p-value: 0.0\n",
      "Kolmogorov-Smirnov test for \u001b[96mcampaign\u001b[00m:\n",
      "KS Statistic: 0.9999778814890181, p-value: 0.0\n",
      "Kolmogorov-Smirnov test for \u001b[96mpdays\u001b[00m:\n",
      "KS Statistic: 0.8173674548229414, p-value: 0.0\n",
      "Kolmogorov-Smirnov test for \u001b[96mprevious\u001b[00m:\n",
      "KS Statistic: 0.18261042666607674, p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Kolmogorov-Smirnov test to check if two distributions are the same\n",
    "\n",
    "def ks_test_column(original_column, processed_column):\n",
    "    # Drop any missing values from original column\n",
    "    original_non_missing = original_column.dropna()\n",
    "    # Kolmogorov-Smirnov test\n",
    "    ks_stat, p_value = ks_2samp(original_non_missing, processed_column)\n",
    "    print(f\"Kolmogorov-Smirnov test for \\033[96m{original_column.name}\\033[00m:\")\n",
    "    print(f\"KS Statistic: {ks_stat}, p-value: {p_value}\")\n",
    "    return ks_stat, p_value\n",
    "\n",
    "# Apply the KS test to all numerical columns\n",
    "for col in numerical_columns:\n",
    "    ks_test_column(merged_df[col], processed_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary  \n",
    "The KS test results suggest that the transformations applied to the numerical columns in your dataset did not alter their distributions. This outcome implies that the preprocessing steps (including scaling or imputation) did not change the fundamental distribution of the data in each column. Therefore, the original and processed data distributions are effectively identical for these columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Test for Categorical Columns\n",
    "\n",
    "#### Interpretation\n",
    "- **Chi-Square Statistic**: Measures the magnitude of the difference between observed and expected frequencies. A higher value indicates a greater difference.    \n",
    "- **P-value**: Indicates the probability of observing the data if the null hypothesis (that the distributions are the same) is true. A low p-value (typically < 0.05) suggests that there is a significant difference between the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square test for \u001b[96mjob\u001b[00m:\n",
      "Chi-Square Statistic: 497321.0, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mmarital\u001b[00m:\n",
      "Chi-Square Statistic: 90422.0, p-value: 0.0\n",
      "Chi-Square test for \u001b[96meducation\u001b[00m:\n",
      "Chi-Square Statistic: 135633.0, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mdefault\u001b[00m:\n",
      "Chi-Square Statistic: 45154.52566979986, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mhousing\u001b[00m:\n",
      "Chi-Square Statistic: 45206.949574261984, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mloan\u001b[00m:\n",
      "Chi-Square Statistic: 45203.568343050356, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mcontact\u001b[00m:\n",
      "Chi-Square Statistic: 90422.0, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mday\u001b[00m:\n",
      "Chi-Square Statistic: 1356330.0, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mmonth\u001b[00m:\n",
      "Chi-Square Statistic: 497321.0, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mpoutcome\u001b[00m:\n",
      "Chi-Square Statistic: 135633.0, p-value: 0.0\n",
      "Chi-Square test for \u001b[96mtotal_loans\u001b[00m:\n",
      "Chi-Square Statistic: 472650.00000000035, p-value: 0.0002096284415473288\n",
      "Chi-Square test for \u001b[96mloan_category\u001b[00m:\n",
      "Chi-Square Statistic: 2760.0000000000005, p-value: 0.0\n",
      "Chi-Square test for \u001b[96msubscribed_to_term_deposit\u001b[00m:\n",
      "Chi-Square Statistic: 45201.31991612434, p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi2_test_column(original_column, processed_column):\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(original_column, processed_column)\n",
    "    \n",
    "    # Perform Chi-Square Test\n",
    "    chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"Chi-Square test for \\033[96m{original_column.name}\\033[00m:\")\n",
    "    print(f\"Chi-Square Statistic: {chi2_stat}, p-value: {p_value}\")\n",
    "    return chi2_stat, p_value\n",
    "\n",
    "# Apply the Chi-Square test to all categorical columns\n",
    "for col in categorical_columns:\n",
    "    chi2_test_column(merged_df[col], processed_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**  \n",
    "After running the Chi-Square Test, you will be able to determine if the categorical distributions in your original and processed datasets are statistically significantly different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 2\n",
    ".... continueeeee "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
