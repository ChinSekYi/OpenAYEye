{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confluence Documentation: https://openayeye.atlassian.net/wiki/x/AYAs\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Merging 1](#Merging-1)\n",
    "    1. [Filling in missing data](#Filling-in-missing-data)\n",
    "    2. [Check if distribution is preserved](#Check-if-distribution-is-preserved)\n",
    "2. [Merging 2](#Merging-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/bank-full.csv\", sep = \";\", header = 0) #from UCI Bank Marketing\n",
    "df2 = pd.read_csv(\"data/Churn_Modelling.csv\").iloc[:, 1:] #from data.gov Total Loans to Non-Bank Customers by Type\n",
    "# df1\n",
    "\n",
    "df1.rename({i:i.lower() for i in df2.columns.values}, axis=1, inplace=True)\n",
    "df2.rename({i:i.lower() for i in df2.columns.values}, axis=1, inplace=True)\n",
    "\n",
    "dtype_dict = pd.DataFrame(pd.concat([df1.dtypes, (df2.dtypes)], axis=0))\n",
    "dtype_dict = dtype_dict.T.loc[:, ~dtype_dict.T.columns.duplicated()].T.copy().iloc[:, 0]\n",
    "# dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Dataframes\n",
    "merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "# print(merged_df['isactivemember'])\n",
    "\n",
    "# Find numerical & categorical columns\n",
    "which_object = [i == np.dtype('O') for i in merged_df.dtypes]\n",
    "categorical_columns = merged_df.columns[which_object].values\n",
    "numerical_columns = merged_df.columns[np.invert(which_object)].values\n",
    "all_columns = np.concatenate([numerical_columns, categorical_columns])\n",
    "\n",
    "# Rearrange column sequence\n",
    "merged_df = merged_df.loc[:, all_columns]\n",
    "merged_df.reset_index(drop=True)\n",
    "merged_df[categorical_columns] = merged_df.loc[:, categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': CategoricalDtype(categories=['admin.', 'blue-collar', 'entrepreneur', 'housemaid',\n",
       "                   'management', 'retired', 'self-employed', 'services',\n",
       "                   'student', 'technician', 'unemployed', 'unknown'],\n",
       " , ordered=False, categories_dtype=object),\n",
       " 'marital': CategoricalDtype(categories=['divorced', 'married', 'single'], ordered=False, categories_dtype=object),\n",
       " 'education': CategoricalDtype(categories=['primary', 'secondary', 'tertiary', 'unknown'], ordered=False, categories_dtype=object),\n",
       " 'default': CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object),\n",
       " 'housing': CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object),\n",
       " 'loan': CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object),\n",
       " 'contact': CategoricalDtype(categories=['cellular', 'telephone', 'unknown'], ordered=False, categories_dtype=object),\n",
       " 'month': CategoricalDtype(categories=['apr', 'aug', 'dec', 'feb', 'jan', 'jul', 'jun', 'mar',\n",
       "                   'may', 'nov', 'oct', 'sep'],\n",
       " , ordered=False, categories_dtype=object),\n",
       " 'poutcome': CategoricalDtype(categories=['failure', 'other', 'success', 'unknown'], ordered=False, categories_dtype=object),\n",
       " 'subscribed': CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object),\n",
       " 'surname': CategoricalDtype(categories=['Abazu', 'Abbie', 'Abbott', 'Abdullah', 'Abdulov', 'Abel',\n",
       "                   'Abernathy', 'Abramov', 'Abramova', 'Abramovich',\n",
       "                   ...\n",
       "                   'Zinachukwudi', 'Zito', 'Zotov', 'Zotova', 'Zox', 'Zubarev',\n",
       "                   'Zubareva', 'Zuev', 'Zuyev', 'Zuyeva'],\n",
       " , ordered=False, categories_dtype=object),\n",
       " 'geography': CategoricalDtype(categories=['France', 'Germany', 'Spain'], ordered=False, categories_dtype=object),\n",
       " 'gender': CategoricalDtype(categories=['Female', 'Male'], ordered=False, categories_dtype=object),\n",
       " 'hascrcard': CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object),\n",
       " 'isactivemember': CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object),\n",
       " 'exited': CategoricalDtype(categories=['no', 'yes'], ordered=False, categories_dtype=object),\n",
       " 'age': dtype('int64'),\n",
       " 'balance': dtype('float64'),\n",
       " 'day': dtype('int64'),\n",
       " 'duration': dtype('int64'),\n",
       " 'campaign': dtype('int64'),\n",
       " 'pdays': dtype('int64'),\n",
       " 'previous': dtype('int64'),\n",
       " 'customerid': dtype('int64'),\n",
       " 'creditscore': dtype('int64'),\n",
       " 'tenure': dtype('int64'),\n",
       " 'numofproducts': dtype('int64'),\n",
       " 'estimatedsalary': dtype('float64')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dtypes = merged_df.dtypes[categorical_columns]\n",
    "num_dtypes = dtype_dict[numerical_columns]\n",
    "dtype_dict = dict(cat_dtypes) |  dict(num_dtypes)\n",
    "dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>subscribed</th>\n",
       "      <th>surname</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job  marital  education default housing loan  contact month  \\\n",
       "0    management  married   tertiary      no     yes   no  unknown   may   \n",
       "1    technician   single  secondary      no     yes   no  unknown   may   \n",
       "2  entrepreneur  married  secondary      no     yes  yes  unknown   may   \n",
       "3   blue-collar  married    unknown      no     yes   no  unknown   may   \n",
       "4       unknown   single    unknown      no      no   no  unknown   may   \n",
       "\n",
       "  poutcome subscribed surname geography gender hascrcard isactivemember exited  \n",
       "0  unknown         no     NaN       NaN    NaN       NaN            NaN    NaN  \n",
       "1  unknown         no     NaN       NaN    NaN       NaN            NaN    NaN  \n",
       "2  unknown         no     NaN       NaN    NaN       NaN            NaN    NaN  \n",
       "3  unknown         no     NaN       NaN    NaN       NaN            NaN    NaN  \n",
       "4  unknown         no     NaN       NaN    NaN       NaN            NaN    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.loc[:, categorical_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>customerid</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>tenure</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>estimatedsalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  day  duration  campaign  pdays  previous  customerid  \\\n",
       "0   58   2143.0  5.0     261.0       1.0   -1.0       0.0         NaN   \n",
       "1   44     29.0  5.0     151.0       1.0   -1.0       0.0         NaN   \n",
       "2   33      2.0  5.0      76.0       1.0   -1.0       0.0         NaN   \n",
       "3   47   1506.0  5.0      92.0       1.0   -1.0       0.0         NaN   \n",
       "4   33      1.0  5.0     198.0       1.0   -1.0       0.0         NaN   \n",
       "\n",
       "   creditscore  tenure  numofproducts  estimatedsalary  \n",
       "0          NaN     NaN            NaN              NaN  \n",
       "1          NaN     NaN            NaN              NaN  \n",
       "2          NaN     NaN            NaN              NaN  \n",
       "3          NaN     NaN            NaN              NaN  \n",
       "4          NaN     NaN            NaN              NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.loc[:, numerical_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate numerical_columns and categorical_columns, as we'll be dealing with missing data in them differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing data\n",
    "Use different techniques to \"fill in missing data\"   \n",
    "Imputers will generate synthetic data based on existing features and use it to fill up the empty cells.\n",
    "Below, I used IterativeImputer for numerical data and SimpleImputer(\"most_frequent\") for categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", IterativeImputer(random_state=0)), # (Multivariate Imputation)\n",
    "                    # Some examples of other imputation methods:\n",
    "                    #   (\"imputer\", SimpleImputer(strategy='mean')), \n",
    "                    #   (\"imputer\", SimpleImputer(strategy='median')), \n",
    "                    #   (\"imputer\", SimpleImputer(strategy='most_frequent')), \n",
    "                    # (\"scaler\", MinMaxScaler()), # Scaling numerical data\n",
    "                ]\n",
    "            )\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        # Some examples of other imputation methods:\n",
    "        # (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),  \n",
    "        # (\"imputer\", KNNImputer(n_neighbors=5, weights=\"uniform\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num_pipeline\", num_pipeline, numerical_columns),\n",
    "                    (\"cat_pipeline\", cat_pipeline, categorical_columns),\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55211, 28) (55211, 28)\n",
      "   age  balance  day  duration  campaign  pdays  previous  customerid  \\\n",
      "0   58   2143.0    5       261         1     -1         0    15691503   \n",
      "1   44     29.0    5       151         1     -1         0    15691519   \n",
      "2   33      2.0    5        76         1     -1         0    15691520   \n",
      "3   47   1506.0    5        92         1     -1         0    15691508   \n",
      "4   33      1.0    5       198         1     -1         0    15691520   \n",
      "\n",
      "   creditscore  tenure  ...  contact  month poutcome subscribed surname  \\\n",
      "0          649       5  ...  unknown    may  unknown         no   Smith   \n",
      "1          649       5  ...  unknown    may  unknown         no   Smith   \n",
      "2          649       5  ...  unknown    may  unknown         no   Smith   \n",
      "3          649       5  ...  unknown    may  unknown         no   Smith   \n",
      "4          649       5  ...  unknown    may  unknown         no   Smith   \n",
      "\n",
      "  geography gender hascrcard isactivemember exited  \n",
      "0    France   Male       yes            yes     no  \n",
      "1    France   Male       yes            yes     no  \n",
      "2    France   Male       yes            yes     no  \n",
      "3    France   Male       yes            yes     no  \n",
      "4    France   Male       yes            yes     no  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply transformation on dataset\n",
    "processed_data = preprocessor.fit_transform(merged_df)\n",
    "\n",
    "# Convert processed_data back to a DataFrame\n",
    "processed_df = pd.DataFrame(processed_data, columns=all_columns)\n",
    "\n",
    "# Convert numerical columns back to float\n",
    "processed_df.loc[:, numerical_columns] = processed_df[numerical_columns].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "processed_df = processed_df.astype(dtype_dict)\n",
    "print(processed_df.shape, merged_df.shape)\n",
    "print(processed_df.head())\n",
    "# print(processed_df.dtypes)\n",
    "processed_df.to_csv(\"data/processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged_df.shape should equal to processed_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if distribution is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eg. Kolmogorov-Smirnov Test for Numerical Columns\n",
    "#### Interpretation  \n",
    "- **KS Statistic**: A KS statistic of 0.0 indicates that there is no difference between the distributions of the original and processed data for each column.  \n",
    "- **P-value**: A p-value of 1.0 means that the test results are consistent with the null hypothesis, which states that the distributions of the two datasets are the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Kolmogorov-Smirnov test to check if two distributions are the same\n",
    "\n",
    "def ks_test_column(original_column, processed_column):\n",
    "    # Drop any missing values from original column\n",
    "    original_non_missing = original_column.dropna()\n",
    "    # Kolmogorov-Smirnov test\n",
    "    ks_stat, p_value = ks_2samp(original_non_missing, processed_column)\n",
    "    print(f\"Kolmogorov-Smirnov test for \\033[96m{original_column.name}\\033[00m:\")\n",
    "    print(f\"KS Statistic: {ks_stat}, p-value: {p_value:.3f}\")\n",
    "    return ks_stat, p_value\n",
    "\n",
    "# Apply the KS test to all numerical columns\n",
    "for col in numerical_columns:\n",
    "    ks_test_column(merged_df[col], processed_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary  \n",
    "The KS test results suggest that the transformations applied to the numerical columns in your dataset did not alter their distributions. This outcome implies that the preprocessing steps (including scaling or imputation) did not change the fundamental distribution of the data in each column. Therefore, the original and processed data distributions are effectively identical for these columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Test for Categorical Columns\n",
    "\n",
    "#### Interpretation\n",
    "- **Chi-Square Statistic**: Measures the magnitude of the difference between observed and expected frequencies. A higher value indicates a greater difference.    \n",
    "- **P-value**: Indicates the probability of observing the data if the null hypothesis (that the distributions are the same) is true. A low p-value (typically < 0.05) suggests that there is a significant difference between the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import chi2_contingency\n",
    "\n",
    "# def chi2_test_column(original_column, processed_column):\n",
    "#     # Create contingency table\n",
    "#     contingency_table = pd.crosstab(original_column, processed_column)\n",
    "    \n",
    "#     # Perform Chi-Square Test\n",
    "#     chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    \n",
    "#     print(f\"Chi-Square test for \\033[96m{original_column.name}\\033[00m:\")\n",
    "#     print(f\"Chi-Square Statistic: {chi2_stat}, p-value: {p_value:.3f}\")\n",
    "#     return chi2_stat, p_value\n",
    "\n",
    "# # Apply the Chi-Square test to all categorical columns\n",
    "# for col in categorical_columns:\n",
    "#     chi2_test_column(merged_df[col], processed_df[col])\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "print(pd.concat([merged_df['job'].value_counts(), processed_df['job'].value_counts()], axis=1))\n",
    "chisquare(merged_df['job'].value_counts(), processed_df['job'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**  \n",
    "Since all p-values are 0.000, there are significant differences between the observed and expected distributions for each categorical column. \n",
    "This suggests that the transformations or imputations performed have significantly altered the distributions from their original state.\n",
    "\n",
    "<font color='red'>Hence.....we need to find better imputation methods for categorical columns!!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 2\n",
    ".... continueeeee "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
